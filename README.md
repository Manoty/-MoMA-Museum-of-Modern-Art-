# MoMA Analytics - dbt + DuckDB + Streamlit

A complete analytics warehouse for the Museum of Modern Art (MoMA) collection built with dbt, DuckDB, and Streamlit.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Virtual environment (venv)

### Installation

1. Clone/download this project
2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install dbt-core dbt-duckdb streamlit pandas
```

4. Initialize dbt:
```bash
dbt init moma_analytics
# Select duckdb as database
```

5. Add CSV data:
- Place `artworks.csv` and `artists.csv` in `seeds/` folder

### Build the Data Warehouse
```bash
# Load raw data
dbt seed

# Build models
dbt run

# Run tests
dbt test

# Generate docs
dbt docs generate
dbt docs serve
```

### Launch Dashboard
```bash
streamlit run app.py
```

Then open `http://localhost:8501` in your browser.

---

## ğŸ“Š Dashboard Overview

**12 Interactive Analyses:**

1. **Summary** - Collection metrics & overview
2. **Trends** - Acquisitions over time
3. **Medium** - Top materials/techniques
4. **Artists** - Most productive artists
5. **Decade** - Acquisition rates by decade
6. **Nationality-Year** - Geographic trends heatmap
7. **Medium-Trends** - Which mediums were popular when
8. **Geographic** - Country-by-country diversity
9. **Artwork Size** - Size trends over time
10. **Artist Lifespan** - Lifespan vs collection presence
11. **Collection Concentration** - Pareto analysis (how many artists = X%)
12. **Decade Detail** - Detailed breakdown by decade/nationality/medium

---

## ğŸ—ï¸ Data Models (14 Total)

### Staging (2)
- `stg_raw_moma__artists` - Cleaned artist data
- `stg_raw_moma__artworks` - Cleaned artwork data

### Dimensions (2)
- `dim_artist` - Artist dimension with demographics
- `dim_artwork` - Artwork dimension with measurements

### Facts (1)
- `fct_artwork_acquisition` - Complete acquisition facts

### Analytics (9)
- `agg_acquisitions_by_year_nationality`
- `agg_by_medium`
- `agg_by_decade`
- `agg_top_artists`
- `agg_nationality_by_year`
- `agg_medium_by_year`
- `agg_geographic_diversity`
- `agg_artwork_size_by_decade`
- `agg_artist_lifespan_analysis`
- `agg_collection_concentration`
- `agg_decade_detailed_breakdown`

---

## ğŸ“ˆ Key Insights

- **146,007** artworks in collection
- **15,765** unique artists
- Top artist: Ludwig Mies van der Rohe (14,539 works)
- Top medium: Gelatin silver print (15,463 works)
- Top country: American artists dominate
- **Pareto insight**: Top 50 artists = 50% of collection

---

## ğŸ“ Project Structure
```
moma_analytics/
â”œâ”€â”€ dbt_project.yml          # dbt config
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ sources.yml          # Data source definitions
â”‚   â”œâ”€â”€ staging/             # Staging models (2)
â”‚   â””â”€â”€ marts/               # Analytics models (12)
â”œâ”€â”€ seeds/
â”‚   â”œâ”€â”€ artworks.csv         # Raw artworks data
â”‚   â””â”€â”€ artists.csv          # Raw artists data
â”œâ”€â”€ tests/                   # Data quality tests
â”œâ”€â”€ app.py                   # Streamlit dashboard
â”œâ”€â”€ moma_analytics.duckdb    # DuckDB database
â”œâ”€â”€ README.md                # This file
â””â”€â”€ FINAL_REPORT.md          # Full business report
```

---

## ğŸ§ª Testing

All models include data quality tests:
```bash
dbt test
```

Tests include:
- `not_null` on primary keys
- `unique` on IDs
- `accepted_values` on known domains

---

## ğŸ“š Documentation

View dbt documentation:
```bash
dbt docs generate
dbt docs serve
```

Browse at `http://localhost:8000`

---

## ğŸš€ Next Steps

1. **Deploy to Cloud**
   - Move DuckDB to Snowflake/BigQuery
   - Deploy Streamlit to Streamlit Cloud
   - Schedule dbt runs (daily/weekly)

2. **Expand Analytics**
   - Add exhibition data
   - Artist collaboration networks
   - Price/valuation trends

3. **Add Interactivity**
   - Date range filters
   - Artist search
   - PDF report export

4. **Performance**
   - Incremental models for large datasets
   - Query caching
   - Data mart materialization

---

## ğŸ“Š Technology Stack

- **Data Transformation**: dbt 1.11.4
- **Data Warehouse**: DuckDB (local SQLite-like)
- **Dashboard**: Streamlit
- **Language**: SQL + Python
- **Testing**: dbt tests + Python

---

## ğŸ‘¨â€ğŸ’» Author

Built in 4-hour dbt sprint (+ extensions for extra analyses)

---

## ğŸ“ License

Data from MoMA public dataset. Analysis for educational purposes.

---

## ğŸ“§ Support

For issues or questions, check:
- `FINAL_REPORT.md` for business insights
- dbt docs for model descriptions
- Streamlit dashboard for data exploration

---

**Status**: âœ… Production Ready | Last Updated: 2026-02-11